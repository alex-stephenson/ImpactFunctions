stop("Error: 'updated_new_value' column is not present in the data.")
}
resolved_data <- data_final %>%
select(question, check_binding, select_multiple_value = updated_new_value) %>%
filter(!str_detect(question, "/"))
parent_q_correct <- change_response %>%
left_join(resolved_data, by = join_by(question == question, check_binding == check_binding))
combined_new_answers <- parent_q_correct %>%
mutate(new_value = ifelse(is.na(select_multiple_value), new_value, select_multiple_value),
new_value = str_replace_all(new_value, "NA", ""),
new_value = str_squish(new_value)) %>%
distinct()
return(combined_new_answers)
}
change_response <- change_response %>%
mutate(question_stem = str_extract(question, "^[^/]+"))
data <- update_parent_values(change_response)
data
View(data)
change_response$new_value == data$new_value
data <- change_response
data <- data %>%
mutate(
is_parent = !str_detect(question, "/"),
child_option = ifelse(!is_parent, str_remove(question, ".*/"), NA)
)
data <- data %>%
mutate(
is_parent = !str_detect(question, "/"),
child_option = ifelse(!is_parent, str_remove(question, ".*/"), NA)
)
missing_children <- data %>%
filter(!is_parent, new_value == "1") %>%
select(uuid, question_stem, child_option) %>%
distinct()
missing_children
data_updated <- data %>%
filter(is_parent) %>%
left_join(missing_children, by = c("uuid", "question_stem")) %>%
group_by(uuid, question_stem) %>%
mutate(
# Combine the parent value and missing child options
updated_new_value = paste(
unique(c(str_split(new_value, "\\s+")[[1]], child_option.x, child_option.y)),
collapse = " "
)
) %>%
ungroup()
data_updated
update_parent_values <- function(data, tool_path, survey_sheet = "survey") {
## lets first make sure we're only using select multiple questions
kobo_survey <- tryCatch(read_excel(tool_path, sheet = survey_sheet, .name_repair = "unique_quiet"),
error = function(e) stop("Error reading survey sheet: ", e))
kobo_survey_sm <- kobo_survey %>%
filter(str_detect(type, "multiple")) %>%
pull(name)
data<- data %>%
filter(question %in% kobo_survey_sm,
change_type == "change_response") %>%
mutate(question_stem = str_extract(question, "^[^/]+"))
# Identify the parent rows (those without '/') and child rows (those with '/')
data <- data %>%
mutate(
is_parent = !str_detect(question, "/"),
child_option = ifelse(!is_parent, str_remove(question, ".*/"), NA)
)
# Get the parent rows that have missing child options
missing_children <- data %>%
filter(!is_parent, new_value == "1") %>%
select(uuid, question_stem, child_option) %>%
distinct()
# Ensure the 'child_option' is retained after the join
data_updated <- data %>%
filter(is_parent) %>%
left_join(missing_children, by = c("uuid", "question_stem")) %>%
group_by(uuid, question_stem) %>%
mutate(
# Combine the parent value and missing child options
updated_new_value = paste(
unique(c(str_split(new_value, "\\s+")[[1]], child_option.x, child_option.y)),
collapse = " "
)
) %>%
ungroup()
# Check if the 'updated_new_value' exists and fix the issue by using proper column names
if("updated_new_value" %in% colnames(data_updated)) {
data_final <- data_updated %>%
bind_rows(data %>% filter(!is_parent)) %>%
distinct() %>%
filter(!is.na(uuid) & !is.na(question)) %>%
arrange(uuid, question)
} else {
stop("Error: 'updated_new_value' column is not present in the data.")
}
resolved_data <- data_final %>%
select(question, check_binding, select_multiple_value = updated_new_value) %>%
filter(!str_detect(question, "/"))
parent_q_correct <- change_response %>%
left_join(resolved_data, by = join_by(question == question, check_binding == check_binding))
combined_new_answers <- parent_q_correct %>%
mutate(new_value = ifelse(is.na(select_multiple_value), new_value, select_multiple_value),
new_value = str_replace_all(new_value, "NA", ""),
new_value = str_squish(new_value)) %>%
distinct()
return(combined_new_answers)
}
update_parent_values(data = combined_clogs,
tool_path =  "C:\Users\alex.stephenson\ACTED\IMPACT SOM - 01_REACH\2024_25\01_ISU\SOM1901_HSM\03_Data & Data Analysis\DEC_24\00_tool\SOM_REACH_HSM_December_2024_Tool_Pilot_ver_AS_EDITS_v2.xlsx"
update_parent_values(data = combined_clogs,
tool_path =  r"(C:\Users\alex.stephenson\ACTED\IMPACT SOM - 01_REACH\2024_25\01_ISU\SOM1901_HSM\03_Data & Data Analysis\DEC_24\00_tool\SOM_REACH_HSM_December_2024_Tool_Pilot_ver_AS_EDITS_v2.xlsx)"
)
library(readxl)
update_parent_values <- function(data, tool_path, survey_sheet = "survey") {
## lets first make sure we're only using select multiple questions
kobo_survey <- tryCatch(read_excel(tool_path, sheet = survey_sheet, .name_repair = "unique_quiet"),
error = function(e) stop("Error reading survey sheet: ", e))
kobo_survey_sm <- kobo_survey %>%
filter(str_detect(type, "multiple")) %>%
pull(name)
data<- data %>%
filter(question %in% kobo_survey_sm,
change_type == "change_response") %>%
mutate(question_stem = str_extract(question, "^[^/]+"))
# Identify the parent rows (those without '/') and child rows (those with '/')
data <- data %>%
mutate(
is_parent = !str_detect(question, "/"),
child_option = ifelse(!is_parent, str_remove(question, ".*/"), NA)
)
# Get the parent rows that have missing child options
missing_children <- data %>%
filter(!is_parent, new_value == "1") %>%
select(uuid, question_stem, child_option) %>%
distinct()
# Ensure the 'child_option' is retained after the join
data_updated <- data %>%
filter(is_parent) %>%
left_join(missing_children, by = c("uuid", "question_stem")) %>%
group_by(uuid, question_stem) %>%
mutate(
# Combine the parent value and missing child options
updated_new_value = paste(
unique(c(str_split(new_value, "\\s+")[[1]], child_option.x, child_option.y)),
collapse = " "
)
) %>%
ungroup()
# Check if the 'updated_new_value' exists and fix the issue by using proper column names
if("updated_new_value" %in% colnames(data_updated)) {
data_final <- data_updated %>%
bind_rows(data %>% filter(!is_parent)) %>%
distinct() %>%
filter(!is.na(uuid) & !is.na(question)) %>%
arrange(uuid, question)
} else {
stop("Error: 'updated_new_value' column is not present in the data.")
}
resolved_data <- data_final %>%
select(question, check_binding, select_multiple_value = updated_new_value) %>%
filter(!str_detect(question, "/"))
parent_q_correct <- change_response %>%
left_join(resolved_data, by = join_by(question == question, check_binding == check_binding))
combined_new_answers <- parent_q_correct %>%
mutate(new_value = ifelse(is.na(select_multiple_value), new_value, select_multiple_value),
new_value = str_replace_all(new_value, "NA", ""),
new_value = str_squish(new_value)) %>%
distinct()
return(combined_new_answers)
}
update_parent_values(data = combined_clogs,
tool_path =  r"(C:\Users\alex.stephenson\ACTED\IMPACT SOM - 01_REACH\2024_25\01_ISU\SOM1901_HSM\03_Data & Data Analysis\DEC_24\00_tool\SOM_REACH_HSM_December_2024_Tool_Pilot_ver_AS_EDITS_v2.xlsx)"
)
?robotoolbox::kobo_audit
?cleaningtools::add_duration_from_audit()
cleaningtools::add_duration_from_audit
audit_files <- robotoolbox::kobo_audit(x = "aDq64HbUFujj63LxMCp5mS", progress = T)
audit_files <- robotoolbox::kobo_audit(x = "amnDUBvDnga4UYnYU4g5kz", progress = T)
library(robotoolbox)
robotoolbox::kobo_audit(x = "amnDUBvDnga4UYnYU4g5kz", progress = T)
robotoolbox::kobo_setup()
kobo_setup(url = "https://kobo.impact-initiatives.org", token = "2d9dadbdca5609632f7dcb76392f1737e6dec598")
audit_files <- robotoolbox::kobo_audit(x = "amnDUBvDnga4UYnYU4g5kz", progress = T)
audit_files <- robotoolbox::kobo_audit(x = "aDq64HbUFujj63LxMCp5mS", progress = T)
audit_files <- robotoolbox::kobo_audit(x = "a38DR4AhAH2rDqP6e5YHLm", progress = T)
audit_files <- robotoolbox::kobo_audit(x = "antAdT3siLrnjTdfcdYcFY", progress = T)
kobo_setup
kobo_settings()
kobo_settings_output <- kobo_settings()
kobo_settings_output$token
?Sys.setenv
?left_join
#' Calculate stratified sample
#' @description Adds the duration of each interview as a column to your dataset based on the metadata logs
#' @param dataset the name of your survey dataframe.
#' @param asset_id the id of your kobo object. Can be taken from your survey URL.
#' @param kobo_token your kobo API key. Optional in case it is already set as a system variable.
#' @param remove_geo whether to remove time taken to get gps coordinates from the summary. Defaults to TRUE.
#' @export
#' @examples
get_kobo_metadata <- function(dataset, asset_id, kobo_token = NULL, remove_geo = TRUE) {
if (is.na(kobo_settings_output$token)) {
if (is.null(kobo_token)) {
stop("Please provide your Kobo API key to kobo_token parameter")
}
kobo_setup(url = "https://kobo.impact-initiatives.org", token = kobo_token)
}
audit_files <- robotoolbox::kobo_audit(x = asset_id, progress = T)
audit_files_length <- audit_files %>%
dplyr::mutate(metadata_duration = (end_int - start_int ) / 60000)
if (remove_geo) {
audit_files_length <- audit_files_length %>%
dplyr::filter(!str_detect(node, "geo"))
}
iv_lengths <- audit_files_length %>%
dplyr::group_by(`_id`) %>%
dplyr::summarise(interview_duration = sum(metadata_duration, na.rm = T),
start_time_metadata = first(start))
data_in_processing <- data_in_processing %>%
dplyr::left_join(iv_lengths)
}
# Load required packages
library(readxl)
library(dplyr)
library(tidyr)
library(stringi)
library(purrr)
# Set seed for reproducibility
set.seed(123)
# Generate random but plausible text response
generate_text <- function() {
words <- c("lorem", "ipsum", "dolor", "sit", "amet",
"consectetur", "adipiscing", "elit", "sed", "do", "eiusmod")
num_words <- sample(3:6, 1)
return(paste(sample(words, num_words, replace = TRUE), collapse = " "))
}
# Generate a select_one answer by sampling one option
generate_select_one <- function(options) {
return(sample(options, 1))
}
# Generate a select_multiple answer by sampling one or more options
generate_select_multiple <- function(options, max_count = length(options)) {
# Pick a random number of options between 1 and max_count
n <- sample(1:max_count, 1)
return(sample(options, n))
}
# Generate a realistic geopoint (latitude and longitude as a space-separated string)
generate_geopoint <- function() {
lat <- runif(1, min = -90, max = 90)
lon <- runif(1, min = -180, max = 180)
return(paste(lat, lon))
}
# Evaluate a relevance condition against current responses.
# Assumes conditions are provided as simple R expressions, e.g., "prev_question == 'yes'"
evaluate_relevance <- function(condition, current_responses) {
if(is.na(condition) || condition == "") return(TRUE)
env <- list2env(current_responses, parent = emptyenv())
result <- tryCatch(eval(parse(text = condition), envir = env), error = function(e) FALSE)
return(isTRUE(result))
}
# Enforce a constraint by evaluating an R expression that should return TRUE for valid values.
# The generated value is stored as "value" in the evaluation environment.
enforce_constraint <- function(value, constraint_expr, current_responses) {
if(is.na(constraint_expr) || constraint_expr == "") return(TRUE)
env <- list2env(current_responses, parent = emptyenv())
env$value <- value
result <- tryCatch(eval(parse(text = constraint_expr), envir = env), error = function(e) FALSE)
return(isTRUE(result))
}
generate_response <- function(survey_df, choices_df, current_responses = list()) {
response <- current_responses
i <- 1
while(i <= nrow(survey_df)) {
row <- survey_df[i, ]
name <- as.character(row$name)
type <- as.character(row$type)
constraint <- ifelse(!is.na(row$constraint), as.character(row$constraint), "")
relevant <- ifelse(!is.na(row$relevant), as.character(row$relevant), "")
# Skip this question if relevance condition is not met
if(!evaluate_relevance(relevant, response)) {
i <- i + 1
next
}
# ----- Handle Repeat Groups -----
if(grepl("begin_repeat", type)) {
# Determine the number of repeats: either a fixed number or based on a previous answer
repeat_count <- if(!is.na(row$repeat_count) && row$repeat_count != "") {
if(grepl("^[0-9]+$", row$repeat_count)) {
as.numeric(row$repeat_count)
} else {
as.numeric(response[[row$repeat_count]])
}
} else {
1
}
# Collect rows belonging to this repeat group until "end_repeat" is encountered
repeat_group_rows <- list()
i <- i + 1
while(i <= nrow(survey_df) && !grepl("end_repeat", survey_df$type[i])) {
repeat_group_rows[[length(repeat_group_rows) + 1]] <- survey_df[i, ]
i <- i + 1
}
# Convert list of rows to a dataframe
repeat_group_df <- bind_rows(repeat_group_rows)
# Generate dummy data for each repeat instance
repeat_data <- vector("list", repeat_count)
for(r in 1:repeat_count) {
rep_response <- generate_response(repeat_group_df, choices_df, response)
repeat_data[[r]] <- rep_response
}
response[[name]] <- repeat_data
# Skip the "end_repeat" row
i <- i + 1
next
}
# Skip "end_repeat" type rows
if(grepl("end_repeat", type)) {
i <- i + 1
next
}
# ----- Process Individual Question Types -----
if(grepl("^text", type)) {
value <- generate_text()
while(!enforce_constraint(value, constraint, response)) {
value <- generate_text()
}
response[[name]] <- value
} else if(grepl("^select_one", type)) {
# Assume type is formatted as "select_one listname"
parts <- strsplit(type, " ")[[1]]
list_name <- parts[2]
options <- choices_df %>% filter(.data$list_name == list_name) %>% pull(name)
value <- generate_select_one(options)
while(!enforce_constraint(value, constraint, response)) {
value <- generate_select_one(options)
}
response[[name]] <- value
} else if(grepl("^select_multiple", type)) {
parts <- strsplit(type, " ")[[1]]
list_name <- parts[2]
options <- choices_df %>% filter(.data$list_name == list_name) %>% pull(name)
value <- generate_select_multiple(options, max_count = length(options))
while(!enforce_constraint(value, constraint, response)) {
value <- generate_select_multiple(options, max_count = length(options))
}
response[[name]] <- value
} else if(grepl("^geopoint", type)) {
value <- generate_geopoint()
while(!enforce_constraint(value, constraint, response)) {
value <- generate_geopoint()
}
response[[name]] <- value
} else if(grepl("^integer", type)) {
# Generate a random integer between 1 and 10 as a default.
value <- sample(1:10, 1)
while(!enforce_constraint(value, constraint, response)) {
value <- sample(1:10, 1)
}
response[[name]] <- value
} else {
# If additional question types are needed, add corresponding logic here.
response[[name]] <- NA
}
i <- i + 1
}
return(response)
}
generate_dummy_data <- function(survey_path,
sheet_survey = "survey",
sheet_choices = "choices",
n_responses = 10) {
# Read survey and choices sheets from the XLSForm
survey_df <- readxl::read_excel(survey_path, sheet = sheet_survey)
choices_df <- readxl::read_excel(survey_path, sheet = sheet_choices)
# Generate a list of responses
responses_list <- vector("list", n_responses)
for(i in 1:n_responses) {
responses_list[[i]] <- generate_response(survey_df, choices_df)
}
# NOTE: Flattening nested repeat groups into a single dataframe may require additional processing.
# For demonstration, we return the list of responses.
return(responses_list)
}
survey_file_path <- "C:\Users\alex.stephenson\Downloads/REACH_2024_SOM_DSRA_Survey_Tool_28_2_2024_RO_AI.xlsx"
# Replace with the actual path to your XLSForm
survey_file_path <- r"(C:\Users\alex.stephenson\Downloads/REACH_2024_SOM_DSRA_Survey_Tool_28_2_2024_RO_AI.xlsx)"
# Generate 5 dummy survey responses
dummy_responses <- generate_dummy_data(survey_file_path, n_responses = 5)
dummy_responses <- generate_dummy_data(survey_file_path, n_responses = 5)
get_kobo_metadata <- function(dataset, asset_id, kobo_token = NULL, remove_geo = TRUE) {
if (is.na(kobo_settings_output$token)) {
if (is.null(kobo_token)) {
stop("Please provide your Kobo API key to kobo_token parameter")
}
kobo_setup(url = "https://kobo.impact-initiatives.org", token = kobo_token)
}
audit_files <- robotoolbox::kobo_audit(x = asset_id, progress = T)
audit_files_length <- audit_files %>%
dplyr::mutate(metadata_duration = (end_int - start_int ) / 60000)
if (remove_geo) {
audit_files_length <- audit_files_length %>%
dplyr::filter(!str_detect(node, "geo"))
}
iv_lengths <- audit_files_length %>%
dplyr::group_by(`_id`) %>%
dplyr::summarise(interview_duration = sum(metadata_duration, na.rm = T),
start_time_metadata = first(start))
data_in_processing <- data_in_processing %>%
dplyr::left_join(iv_lengths)
}
readxl::read_excel(r"(C:\Users\alex.stephenson\ACTED\IMPACT SOM - 01_REACH\2024_25\01_ISU\SOM1901_HSM\03_Data & Data Analysis\DEC_24\01CLeaning scripts\_code\outputs\dashboard/unchecked_data_for_dashboard_Jan_05_2025_131513.xlsx)")
test_data <- readxl::read_excel(r"(C:\Users\alex.stephenson\ACTED\IMPACT SOM - 01_REACH\2024_25\01_ISU\SOM1901_HSM\03_Data & Data Analysis\DEC_24\01CLeaning scripts\_code\outputs\dashboard/unchecked_data_for_dashboard_Jan_05_2025_131513.xlsx)")
get_kobo_metadata(dataset = test_data, asset_id = "amnDUBvDnga4UYnYU4g5kz")
get_kobo_metadata(dataset = test_data, asset_id = "amnDUBvDnga4UYnYU4g5kz")
get_kobo_metadata <- function(dataset, asset_id, kobo_token = NULL, remove_geo = TRUE) {
if (is.na(kobo_settings_output$token)) {
if (is.null(kobo_token)) {
stop("Please provide your Kobo API key to kobo_token parameter")
}
kobo_setup(url = "https://kobo.impact-initiatives.org", token = kobo_token)
}
audit_files <- robotoolbox::kobo_audit(x = asset_id, progress = T)
audit_files_length <- audit_files %>%
dplyr::mutate(metadata_duration = (end_int - start_int ) / 60000)
if (remove_geo) {
audit_files_length <- audit_files_length %>%
dplyr::filter(!str_detect(node, "geo"))
}
iv_lengths <- audit_files_length %>%
dplyr::group_by(`_id`) %>%
dplyr::summarise(interview_duration = sum(metadata_duration, na.rm = T),
start_time_metadata = first(start))
data_in_processing <- data_in_processing %>%
dplyr::left_join(iv_lengths)
return(data_in_processing)
}
kobo_test_output <- get_kobo_metadata(dataset = test_data, asset_id = "amnDUBvDnga4UYnYU4g5kz")
stringr::str_detect
get_kobo_metadata <- function(dataset, asset_id, kobo_token = NULL, remove_geo = TRUE) {
if (is.na(kobo_settings_output$token)) {
if (is.null(kobo_token)) {
stop("Please provide your Kobo API key to kobo_token parameter")
}
kobo_setup(url = "https://kobo.impact-initiatives.org", token = kobo_token)
}
audit_files <- robotoolbox::kobo_audit(x = asset_id, progress = T)
audit_files_length <- audit_files %>%
dplyr::mutate(metadata_duration = (end_int - start_int ) / 60000)
if (remove_geo) {
audit_files_length <- audit_files_length %>%
dplyr::filter(!stringr::str_detect(node, "geo"))
}
iv_lengths <- audit_files_length %>%
dplyr::group_by(`_id`) %>%
dplyr::summarise(interview_duration = sum(metadata_duration, na.rm = T),
start_time_metadata = first(start))
data_in_processing <- data_in_processing %>%
dplyr::left_join(iv_lengths)
return(data_in_processing)
}
kobo_test_output <- get_kobo_metadata(dataset = test_data, asset_id = "amnDUBvDnga4UYnYU4g5kz")
if (is.na(kobo_settings_output$token)) {
if (is.null(kobo_token)) {
stop("Please provide your Kobo API key to kobo_token parameter")
}
kobo_setup(url = "https://kobo.impact-initiatives.org", token = kobo_token)
}
asset_id <- "amnDUBvDnga4UYnYU4g5kz"
audit_files <- robotoolbox::kobo_audit(x = asset_id, progress = T)
audit_files_length <- audit_files %>%
dplyr::mutate(metadata_duration = (end_int - start_int ) / 60000)
if (remove_geo) {
audit_files_length <- audit_files_length %>%
dplyr::filter(!stringr::str_detect(node, "geo"))
}
iv_lengths <- audit_files_length %>%
dplyr::group_by(`_id`) %>%
dplyr::summarise(interview_duration = sum(metadata_duration, na.rm = T),
start_time_metadata = first(start))
data_in_processing <- dataset %>%
dplyr::left_join(iv_lengths)
get_kobo_metadata <- function(dataset, asset_id, kobo_token = NULL, remove_geo = TRUE) {
if (is.na(kobo_settings_output$token)) {
if (is.null(kobo_token)) {
stop("Please provide your Kobo API key to kobo_token parameter")
}
kobo_setup(url = "https://kobo.impact-initiatives.org", token = kobo_token)
}
audit_files <- robotoolbox::kobo_audit(x = asset_id, progress = T)
audit_files_length <- audit_files %>%
dplyr::mutate(metadata_duration = (end_int - start_int ) / 60000)
if (remove_geo) {
audit_files_length <- audit_files_length %>%
dplyr::filter(!stringr::str_detect(node, "geo"))
}
iv_lengths <- audit_files_length %>%
dplyr::group_by(`_id`) %>%
dplyr::summarise(interview_duration = sum(metadata_duration, na.rm = T),
start_time_metadata = first(start))
data_in_processing <- dataset %>%
dplyr::left_join(iv_lengths)
return(data_in_processing)
}
kobo_test_output <- get_kobo_metadata(dataset = test_data, asset_id = "amnDUBvDnga4UYnYU4g5kz")
kobo_test_output
devtools::document()
?document
?document
devtools::document()
devtools::document()
devtools::document()
devtools::document()
remove.packages("ImpactFunctions")
