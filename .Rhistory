value <- sample(1:10, 1)
while(!enforce_constraint(value, constraint, response)) {
value <- sample(1:10, 1)
}
response[[name]] <- value
} else {
# If additional question types are needed, add corresponding logic here.
response[[name]] <- NA
}
i <- i + 1
}
return(response)
}
generate_dummy_data <- function(survey_path,
sheet_survey = "survey",
sheet_choices = "choices",
n_responses = 10) {
# Read survey and choices sheets from the XLSForm
survey_df <- readxl::read_excel(survey_path, sheet = sheet_survey)
choices_df <- readxl::read_excel(survey_path, sheet = sheet_choices)
# Generate a list of responses
responses_list <- vector("list", n_responses)
for(i in 1:n_responses) {
responses_list[[i]] <- generate_response(survey_df, choices_df)
}
# NOTE: Flattening nested repeat groups into a single dataframe may require additional processing.
# For demonstration, we return the list of responses.
return(responses_list)
}
survey_file_path <- "C:\Users\alex.stephenson\Downloads/REACH_2024_SOM_DSRA_Survey_Tool_28_2_2024_RO_AI.xlsx"
# Replace with the actual path to your XLSForm
survey_file_path <- r"(C:\Users\alex.stephenson\Downloads/REACH_2024_SOM_DSRA_Survey_Tool_28_2_2024_RO_AI.xlsx)"
# Generate 5 dummy survey responses
dummy_responses <- generate_dummy_data(survey_file_path, n_responses = 5)
dummy_responses <- generate_dummy_data(survey_file_path, n_responses = 5)
get_kobo_metadata <- function(dataset, asset_id, kobo_token = NULL, remove_geo = TRUE) {
if (is.na(kobo_settings_output$token)) {
if (is.null(kobo_token)) {
stop("Please provide your Kobo API key to kobo_token parameter")
}
kobo_setup(url = "https://kobo.impact-initiatives.org", token = kobo_token)
}
audit_files <- robotoolbox::kobo_audit(x = asset_id, progress = T)
audit_files_length <- audit_files %>%
dplyr::mutate(metadata_duration = (end_int - start_int ) / 60000)
if (remove_geo) {
audit_files_length <- audit_files_length %>%
dplyr::filter(!str_detect(node, "geo"))
}
iv_lengths <- audit_files_length %>%
dplyr::group_by(`_id`) %>%
dplyr::summarise(interview_duration = sum(metadata_duration, na.rm = T),
start_time_metadata = first(start))
data_in_processing <- data_in_processing %>%
dplyr::left_join(iv_lengths)
}
readxl::read_excel(r"(C:\Users\alex.stephenson\ACTED\IMPACT SOM - 01_REACH\2024_25\01_ISU\SOM1901_HSM\03_Data & Data Analysis\DEC_24\01CLeaning scripts\_code\outputs\dashboard/unchecked_data_for_dashboard_Jan_05_2025_131513.xlsx)")
test_data <- readxl::read_excel(r"(C:\Users\alex.stephenson\ACTED\IMPACT SOM - 01_REACH\2024_25\01_ISU\SOM1901_HSM\03_Data & Data Analysis\DEC_24\01CLeaning scripts\_code\outputs\dashboard/unchecked_data_for_dashboard_Jan_05_2025_131513.xlsx)")
get_kobo_metadata(dataset = test_data, asset_id = "amnDUBvDnga4UYnYU4g5kz")
get_kobo_metadata(dataset = test_data, asset_id = "amnDUBvDnga4UYnYU4g5kz")
get_kobo_metadata <- function(dataset, asset_id, kobo_token = NULL, remove_geo = TRUE) {
if (is.na(kobo_settings_output$token)) {
if (is.null(kobo_token)) {
stop("Please provide your Kobo API key to kobo_token parameter")
}
kobo_setup(url = "https://kobo.impact-initiatives.org", token = kobo_token)
}
audit_files <- robotoolbox::kobo_audit(x = asset_id, progress = T)
audit_files_length <- audit_files %>%
dplyr::mutate(metadata_duration = (end_int - start_int ) / 60000)
if (remove_geo) {
audit_files_length <- audit_files_length %>%
dplyr::filter(!str_detect(node, "geo"))
}
iv_lengths <- audit_files_length %>%
dplyr::group_by(`_id`) %>%
dplyr::summarise(interview_duration = sum(metadata_duration, na.rm = T),
start_time_metadata = first(start))
data_in_processing <- data_in_processing %>%
dplyr::left_join(iv_lengths)
return(data_in_processing)
}
kobo_test_output <- get_kobo_metadata(dataset = test_data, asset_id = "amnDUBvDnga4UYnYU4g5kz")
stringr::str_detect
get_kobo_metadata <- function(dataset, asset_id, kobo_token = NULL, remove_geo = TRUE) {
if (is.na(kobo_settings_output$token)) {
if (is.null(kobo_token)) {
stop("Please provide your Kobo API key to kobo_token parameter")
}
kobo_setup(url = "https://kobo.impact-initiatives.org", token = kobo_token)
}
audit_files <- robotoolbox::kobo_audit(x = asset_id, progress = T)
audit_files_length <- audit_files %>%
dplyr::mutate(metadata_duration = (end_int - start_int ) / 60000)
if (remove_geo) {
audit_files_length <- audit_files_length %>%
dplyr::filter(!stringr::str_detect(node, "geo"))
}
iv_lengths <- audit_files_length %>%
dplyr::group_by(`_id`) %>%
dplyr::summarise(interview_duration = sum(metadata_duration, na.rm = T),
start_time_metadata = first(start))
data_in_processing <- data_in_processing %>%
dplyr::left_join(iv_lengths)
return(data_in_processing)
}
kobo_test_output <- get_kobo_metadata(dataset = test_data, asset_id = "amnDUBvDnga4UYnYU4g5kz")
if (is.na(kobo_settings_output$token)) {
if (is.null(kobo_token)) {
stop("Please provide your Kobo API key to kobo_token parameter")
}
kobo_setup(url = "https://kobo.impact-initiatives.org", token = kobo_token)
}
asset_id <- "amnDUBvDnga4UYnYU4g5kz"
audit_files <- robotoolbox::kobo_audit(x = asset_id, progress = T)
audit_files_length <- audit_files %>%
dplyr::mutate(metadata_duration = (end_int - start_int ) / 60000)
if (remove_geo) {
audit_files_length <- audit_files_length %>%
dplyr::filter(!stringr::str_detect(node, "geo"))
}
iv_lengths <- audit_files_length %>%
dplyr::group_by(`_id`) %>%
dplyr::summarise(interview_duration = sum(metadata_duration, na.rm = T),
start_time_metadata = first(start))
data_in_processing <- dataset %>%
dplyr::left_join(iv_lengths)
get_kobo_metadata <- function(dataset, asset_id, kobo_token = NULL, remove_geo = TRUE) {
if (is.na(kobo_settings_output$token)) {
if (is.null(kobo_token)) {
stop("Please provide your Kobo API key to kobo_token parameter")
}
kobo_setup(url = "https://kobo.impact-initiatives.org", token = kobo_token)
}
audit_files <- robotoolbox::kobo_audit(x = asset_id, progress = T)
audit_files_length <- audit_files %>%
dplyr::mutate(metadata_duration = (end_int - start_int ) / 60000)
if (remove_geo) {
audit_files_length <- audit_files_length %>%
dplyr::filter(!stringr::str_detect(node, "geo"))
}
iv_lengths <- audit_files_length %>%
dplyr::group_by(`_id`) %>%
dplyr::summarise(interview_duration = sum(metadata_duration, na.rm = T),
start_time_metadata = first(start))
data_in_processing <- dataset %>%
dplyr::left_join(iv_lengths)
return(data_in_processing)
}
kobo_test_output <- get_kobo_metadata(dataset = test_data, asset_id = "amnDUBvDnga4UYnYU4g5kz")
kobo_test_output
devtools::document()
?document
?document
devtools::document()
devtools::document()
devtools::document()
devtools::document()
remove.packages("ImpactFunctions")
devtools::document()
devtools::document()
devtools::document()
Devtools::install_github(“alex-stephenson/ImpactFunctions”)
Devtools::install_github(“alex-stephenson/ImpactFunctions”)
devtools::install_github(“alex-stephenson/ImpactFunctions”)
devtools::install_github("alex-stephenson/ImpactFunctions")
devtools::document()
devtools::document()
devtools::install()
survey <- read_excel("../../02_Data_Collection/02_Tool/REACH_2025_SOM_DSRA_II_Survey_Tool.xlsx", sheet = "survey")
choices <- read_excel("../../02_Data_Collection/02_Tool/REACH_2025_SOM_DSRA_II_Survey_Tool.xlsx", sheet = "choices")
library(readxl)
library(tidyverse)
## get clogs
# Define directory pattern
dir_path <- "01_cleaning_logs"
all_files <- list.files(
path = dir_path,
recursive = TRUE,
full.names = TRUE
)
file_list <- all_files %>%
keep(~ str_detect(.x, "/[^/]+_complete/") & str_detect(.x, "cleaning_log.*\\.xlsx$") & !str_detect(.x, "report"))
# Function to read and convert all columns to character
read_and_clean <- function(file, sheet) {
read_excel(file, sheet = sheet) %>%
mutate(across(everything(), as.character))  # Convert all columns to character
}
# Read and combine all files into a single dataframe
cleaning_logs <- map_dfr(file_list, sheet = 'cleaning_log', read_and_clean)
cleaning_logs <- cleaning_logs %>%
filter(!is.na(change_type))
## get clogs
# Define directory pattern
dir_path <- "01_cleaning_logs"
all_files <- list.files(
path = dir_path,
recursive = TRUE,
full.names = TRUE
)
file_list <- all_files %>%
keep(~ str_detect(.x, "/[^/]+_complete/") & str_detect(.x, "cleaning_log.*\\.xlsx$") & !str_detect(.x, "report"))
# Function to read and convert all columns to character
read_and_clean <- function(file, sheet) {
read_excel(file, sheet = sheet) %>%
mutate(across(everything(), as.character))  # Convert all columns to character
}
# Read and combine all files into a single dataframe
cleaning_logs <- map_dfr(file_list, sheet = 'cleaning_log', read_and_clean)
cleaning_logs
survey
survey <- read_excel("../../02_Data_Collection/02_Tool/REACH_2025_SOM_DSRA_II_Survey_Tool.xlsx", sheet = "survey")
devtools::document()
devtools::load_all()
"C:\Users\alex.stephenson\ACTED\IMPACT SOM - 01_REACH\2025_26\03_DDSU\01_SOM2401_DSRA II\04_Data\03_DSRA_II_Scripts\02_input/DSRA_II_Tool.csv"
survey <- r"(C:\Users\alex.stephenson\ACTED\IMPACT SOM - 01_REACH\2025_26\03_DDSU\01_SOM2401_DSRA II\04_Data\03_DSRA_II_Scripts\02_input/DSRA_II_Tool.csv)"
tool_path <- r"(C:\Users\alex.stephenson\ACTED\IMPACT SOM - 01_REACH\2025_26\03_DDSU\01_SOM2401_DSRA II\04_Data\03_DSRA_II_Scripts\02_input/DSRA_II_Tool.csv)"
survey <- read_excel(tool_path, sheet = "survey")
tool_path <- r"(C:\Users\alex.stephenson\ACTED\IMPACT SOM - 01_REACH\2025_26\03_DDSU\01_SOM2401_DSRA II\04_Data\03_DSRA_II_Scripts\02_input/DSRA_II_Tool.xlsx)"
survey <- read_excel(tool_path, sheet = "survey")
tool_path <- r"(C:\Users\alex.stephenson\ACTED\IMPACT SOM - 01_REACH\2025_26\03_DDSU\01_SOM2401_DSRA II\04_Data\03_DSRA_II_Scripts\02_input/DSRA_II_Tool.xlsx)"
survey <- read_excel(tool_path, sheet = "survey")
choices <- read_excel(tool_path, sheet = "choices")
dir_path <- r"(C:\Users\alex.stephenson\ACTED\IMPACT SOM - 01_REACH\2025_26\03_DDSU\01_SOM2401_DSRA II\04_Data\03_DSRA_II_Scripts\01_cleaning_logs)"
all_files <- list.files(
path = dir_path,
recursive = TRUE,
full.names = TRUE
)
all_files
file_list <- all_files %>%
keep(~ str_detect(.x, "/[^/]+_complete/") & str_detect(.x, "cleaning_log.*\\.xlsx$") & !str_detect(.x, "report"))
# Function to read and convert all columns to character
read_and_clean <- function(file, sheet) {
read_excel(file, sheet = sheet) %>%
mutate(across(everything(), as.character))  # Convert all columns to character
}
# Read and combine all files into a single dataframe
cleaning_logs <- map_dfr(file_list, sheet = 'cleaning_log', read_and_clean)
cleaning_logs <- cleaning_logs %>%
filter(!is.na(change_type))
}
# Define directory pattern
dir_path <- r"(C:\Users\alex.stephenson\ACTED\IMPACT SOM - 01_REACH\2025_26\03_DDSU\01_SOM2401_DSRA II\04_Data\03_DSRA_II_Scripts\01_cleaning_logs)"
all_files <- list.files(
path = dir_path,
recursive = TRUE,
full.names = TRUE
)
file_list <- all_files %>%
keep(~ str_detect(.x, "/[^/]+_complete/") & str_detect(.x, "cleaning_log.*\\.xlsx$") & !str_detect(.x, "report"))
# Function to read and convert all columns to character
read_and_clean <- function(file, sheet) {
read_excel(file, sheet = sheet) %>%
mutate(across(everything(), as.character))  # Convert all columns to character
}
# Read and combine all files into a single dataframe
cleaning_logs <- map_dfr(file_list, sheet = 'cleaning_log', read_and_clean)
cleaning_logs <- cleaning_logs %>%
filter(!is.na(change_type))
ImpactFunctions::update_others(survey = survey, choices = choices, cleaning_log = cleaning_logs)
devtools::document()
devtools::load_all()
ImpactFunctions::update_others(survey = survey, choices = choices, cleaning_log = cleaning_logs)
?ImpactFunctions::update_others
devtools::document()
devtools::load_all()
?ImpactFunctions::update_others
devtools::document()
devtools::document()
devtools::load_all()
?ImpactFunctions::update_others
raw_data <- data.frame(a = 1:3, b = 4:6, c = 7:9)
clean_data <- data.frame(a = 1:3, d = 10:12)
create_variable_tracker(raw_data, clean_data)
create_variable_tracker <- function(raw_data, clean_data) {
removed_cols <- data.frame(Variable = colnames(raw_data)) %>%
filter(! Variable %in% colnames(clean_data)) %>%
mutate(Action = "remove",
Rationale = "")
new_cols <- data.frame(Variable = colnames(clean_data)) %>%
filter(! Variable %in% colnames(raw_data)) %>%
mutate(Action = "added",
Rationale = "")
variable_tracker <- bind_rows(removed_cols, new_cols)
return(variable_tracker)
}
create_variable_tracker(raw_data, clean_data)
library(dplyr)
create_variable_tracker <- function(raw_data, clean_data) {
removed_cols <- data.frame(Variable = colnames(raw_data)) %>%
filter(! Variable %in% colnames(clean_data)) %>%
mutate(Action = "remove",
Rationale = "")
new_cols <- data.frame(Variable = colnames(clean_data)) %>%
filter(! Variable %in% colnames(raw_data)) %>%
mutate(Action = "added",
Rationale = "")
variable_tracker <- bind_rows(removed_cols, new_cols)
return(variable_tracker)
}
create_variable_tracker(raw_data, clean_data)
devtools::document()
?first
robotoolbox::kobo_token(
username = un,
password = pw,
url = sub("\\/$", "", kobo_server_url)
)
kobo_server_url <- "https://kobo.impact-initiatives.org/"
kobo_server_url <- "https://kobo.impact-initiatives.org/"
kobo_token_value <- robotoolbox::kobo_token(
username = un,
password = pw,
url = sub("\\/$", "", kobo_server_url)
)
kobo_token_value <- robotoolbox::kobo_token(
username = "alex_stephenson",
password = "Ah$24897K080",
url = sub("\\/$", "", kobo_server_url)
)
kobo_token_value
kobo_token_value <- robotoolbox::kobo_token(
username = un,
password = pw,
url = sub("\\/$", "", kobo_server_url)
)
kobo_server_url <- "https://kobo.impact-initiatives.org/"
kobo_token_value <- robotoolbox::kobo_token(
username = un,
password = pw,
url = sub("\\/$", "", kobo_server_url)
)
# Get token and setup Kobo API
kobo_server_url <- "https://kobo.impact-initiatives.org/"
kobo_token_value <- robotoolbox::kobo_token(
username = un,
password = pw,
url = sub("\\/$", "", kobo_server_url)
)
kobo_token_value
robotoolbox::kobo_setup(
url = sub("\\/$", "", kobo_server_url),
token = kobo_token_value
)
?kobo_setup
#' @import robotoolbox
#' @import stringr
#' @import keyring
#'
#' @export
#'
#' @examples
#' \dontrun{
#' get_kobo_metadata(dataset = data_in_processing, asset_id = "abc123XYZ", un = "my_kobo_username")
#' }
get_kobo_metadata <- function(dataset, asset_id, un, remove_geo = TRUE) {
# Try to retrieve password from keyring
pw <- tryCatch({
keyring::key_get(un)
}, error = function(e) {
keyring::key_set(un, prompt = "Please input your Kobo password. You will only have to do this once.")
keyring::key_get(un)
})
# Get token and setup Kobo API
kobo_server_url <- "https://kobo.impact-initiatives.org/"
kobo_token_value <- robotoolbox::kobo_token(
username = un,
password = pw,
url = sub("\\/$", "", kobo_server_url)
)
robotoolbox::kobo_setup(
url = sub("\\/$", "", kobo_server_url),
token = kobo_token_value
)
# Retrieve and process audit files
audit_files <- robotoolbox::kobo_audit(x = asset_id, progress = TRUE)
audit_files_length <- audit_files %>%
dplyr::mutate(metadata_duration = (end_int - start_int) / 60000)
if (remove_geo) {
audit_files_length <- audit_files_length %>%
dplyr::filter(!stringr::str_detect(node, "geo"))
}
iv_lengths <- audit_files_length %>%
dplyr::group_by(`_id`) %>%
dplyr::summarise(
interview_duration = sum(metadata_duration, na.rm = TRUE),
start_time_metadata = first(start),
.groups = "drop"
)
data_in_processing <- dataset %>%
dplyr::left_join(iv_lengths, by = "_id")
return(list(
df_and_duration = data_in_processing,
audit_files_length = audit_files_length
))
}
devtools::document()
rm(list = c("get_kobo_metadata"))
devtools::document()
presentresults::create_table_group_x_variable
presentresults::create_xlsx_group_x_variable()
presentresults::create_xlsx_group_x_variable
?nzchar
# Securely retrieve or prompt for Kobo password
get_password <- function(un) {
if (missing(un) || !is.character(un) || nchar(un) == 0) {
stop("Please provide a valid Kobo username to `un`.")
}
tryCatch({
keyring::key_get(un)
}, error = function(e) {
keyring::key_set(un, prompt = "Please input your Kobo password. You will only have to do this once.")
keyring::key_get(un)
})
}
#' Kobo Server Query Function
#'
#' Retrieve Kobo data from the server by providing the asset ID.
#' @param asset_id Character. The asset ID of the survey.
#' @param un Character. Your Kobo username.
#' @param server_url Character. Kobo server URL (default: "https://kobo.impact-initiatives.org/").
#' @return A data frame of the Kobo survey results. If the survey includes roster questions then it is a list of dataframes, `main` and `hh_roster`.
#' @export
get_kobo_data <- function(asset_id, un, server_url = "https://kobo.impact-initiatives.org/") {
if (missing(asset_id) || !nzchar(asset_id)) {
stop("Please provide a valid asset ID.")
}
if (missing(un) || !nzchar(un)) {
stop("Please provide your Kobo username (`un`).")
}
pw <- get_password(un)
clean_url <- sub("\\/$", "", server_url)
token <- robotoolbox::kobo_token(username = un, password = pw, url = clean_url)
robotoolbox::kobo_setup(url = clean_url, token = token)
asset <- robotoolbox::kobo_asset(asset_id)
robotoolbox::kobo_data(asset, select_multiple_sep = "/")
}
get_kobo_data(asset_id = "a78BPkkB3ZDwihdL5uqd5J", un = "abdirahmanaia")
# Securely retrieve or prompt for Kobo password
get_password <- function(un) {
if (missing(un) || !is.character(un) || nchar(un) == 0) {
stop("Please provide a valid Kobo username to `un`.")
}
tryCatch({
keyring::key_get(un)
}, error = function(e) {
keyring::key_set(un, prompt = "Please input your Kobo password. You will only have to do this once.")
keyring::key_get(un)
})
}
#' Kobo Server Query Function
#'
#' Retrieve Kobo data from the server by providing the asset ID.
#' @param asset_id Character. The asset ID of the survey.
#' @param un Character. Your Kobo username.
#' @param server_url Character. Kobo server URL (default: "https://kobo.impact-initiatives.org/").
#' @return A data frame of the Kobo survey results. If the survey includes roster questions then it is a list of dataframes, `main` and `hh_roster`.
#' @export
get_kobo_data <- function(asset_id, un, server_url = "https://kobo.impact-initiatives.org/") {
if (missing(asset_id) || !nzchar(asset_id)) {
stop("Please provide a valid asset ID.")
}
if (missing(un) || !nzchar(un)) {
stop("Please provide your Kobo username (`un`).")
}
message("Authenticating with Kobo server...")
pw <- get_password(un)
clean_url <- sub("\\/$", "", server_url)
token <- robotoolbox::kobo_token(username = un, password = pw, url = clean_url)
robotoolbox::kobo_setup(url = clean_url, token = token)
message("Downloading data...")
asset <- robotoolbox::kobo_asset(asset_id)
robotoolbox::kobo_data(asset, select_multiple_sep = "/")
}
get_kobo_data(asset_id = "a78BPkkB3ZDwihdL5uqd5J", un = "abdirahmanaia")
?kobo_data
robotoolbox::kobo_data(asset, progress = T, select_multiple_sep = "/")
#' Kobo Server Query Function
#'
#' Retrieve Kobo data from the server by providing the asset ID.
#' @param asset_id Character. The asset ID of the survey.
#' @param un Character. Your Kobo username.
#' @param server_url Character. Kobo server URL (default: "https://kobo.impact-initiatives.org/").
#' @return A data frame of the Kobo survey results. If the survey includes roster questions then it is a list of dataframes, `main` and `hh_roster`.
#' @export
get_kobo_data <- function(asset_id, un, server_url = "https://kobo.impact-initiatives.org/") {
if (missing(asset_id) || !nzchar(asset_id)) {
stop("Please provide a valid asset ID.")
}
if (missing(un) || !nzchar(un)) {
stop("Please provide your Kobo username (`un`).")
}
message("Authenticating with Kobo server...")
pw <- get_password(un)
clean_url <- sub("\\/$", "", server_url)
token <- robotoolbox::kobo_token(username = un, password = pw, url = clean_url)
robotoolbox::kobo_setup(url = clean_url, token = token)
message("Downloading data...")
asset <- robotoolbox::kobo_asset(asset_id)
robotoolbox::kobo_data(asset, progress = T, select_multiple_sep = "/")
}
robotoolbox::kobo_data(asset, progress = T, select_multiple_sep = "/")
get_kobo_data(asset_id = "a78BPkkB3ZDwihdL5uqd5J", un = "abdirahmanaia")
devtools::document()
?devtools::install_github
?summarise
devtools::document()
devtools::document()
devtools::document()
devtools::install_github("alex-stephenson/ImpactFunctions")
ImpactFunctions::update_others
